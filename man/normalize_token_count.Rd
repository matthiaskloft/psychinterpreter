% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils_text_processing.R
\name{normalize_token_count}
\alias{normalize_token_count}
\title{Normalize Token Count to Valid Numeric Value}
\usage{
normalize_token_count(value)
}
\arguments{
\item{value}{Raw token count value (may be NULL, NA, numeric(0), etc.)}
}
\value{
Numeric scalar. Returns 0.0 if input is invalid, otherwise the
numeric value.
}
\description{
Ensures token count values are always valid numeric scalars, handling NULL,
NA, and empty values gracefully. Used for robust token tracking across
different LLM providers that may not consistently report token counts.
}
\details{
Some LLM providers (e.g., Ollama) do not support token tracking and may
return NULL or 0. This function ensures consistent handling across providers
by normalizing all invalid values to 0.0.
}
\examples{
\dontrun{
normalize_token_count(100)        # 100
normalize_token_count(NULL)       # 0
normalize_token_count(NA)         # 0
normalize_token_count(numeric(0)) # 0
}

}
\keyword{internal}
