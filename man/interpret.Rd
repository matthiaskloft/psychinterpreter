% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interpret_methods.R
\name{interpret}
\alias{interpret}
\title{Interpret Psychometric Analysis Results}
\usage{
interpret(model, ...)
}
\arguments{
\item{model}{One of:
\itemize{
\item Fitted model object (psych::fa, lavaan::cfa, mirt::mirt, etc.)
\item Raw model data (loadings matrix, parameters, etc.)
\item chat_session object for multi-analysis workflows
}}

\item{...}{Additional arguments passed to methods, including:
\itemize{
\item variable_info: Dataframe with 'variable' and 'description' columns
\item model_type: Character. Type of analysis ("fa", "gm", "irt", "cdm") when using raw data
\item chat_session: Persistent chat session (created with \code{chat_session()})
\item llm_provider: LLM provider (e.g., "anthropic", "openai")
\item llm_model: Model name (e.g., "claude-haiku-4-5-20251001")
\item Other model-specific parameters (cutoff, word_limit, etc.)
}}
}
\value{
Model-specific interpretation object:
\itemize{
\item FA: \code{fa_interpretation} (see \code{\link{interpret_fa}})
\item Future: \code{gm_interpretation}, \code{irt_interpretation}, etc.
}
}
\description{
Unified interface for interpreting psychometric analysis results with LLMs.
Supports model objects from popular R packages, raw data with model_type specification,
and persistent chat sessions for efficient multi-analysis workflows.
}
\details{
This generic function provides four usage patterns:

\strong{1. Model Object (Automatic Extraction)}
\code{interpret(model_object, variable_info, ...)}
\itemize{
\item Automatically extracts loadings/parameters from fitted models
\item Supported: psych::fa, psych::principal, lavaan::cfa/efa, mirt::mirt
}

\strong{2. Raw Data with model_type}
\code{interpret(data, variable_info, model_type = "fa", ...)}
\itemize{
\item For custom data structures or manual loading matrices
\item Requires explicit model_type specification
}

\strong{3. Persistent Chat Session (Efficient Multi-Analysis)}
\code{interpret(chat_session, model_data, variable_info, ...)}
\itemize{
\item Reuses chat session across multiple analyses
\item Saves tokens by not repeating system prompt
}

\strong{4. Raw Data with chat_session}
\code{interpret(data, variable_info, chat_session = chat, ...)}
\itemize{
\item Combines raw data with persistent session
\item Model type inherited from chat_session
}

\strong{Supported Model Types:}
\itemize{
\item \strong{fa} (Factor Analysis): psych::fa(), psych::principal(), lavaan::cfa/efa(), mirt::mirt()
\item \strong{gm} (Gaussian Mixture): Not yet implemented
\item \strong{irt} (Item Response Theory): Not yet implemented
\item \strong{cdm} (Cognitive Diagnosis Models): Not yet implemented
}
}
\examples{
\dontrun{
# Set up API credentials
Sys.setenv(ANTHROPIC_API_KEY = "your-api-key-here")

var_info <- data.frame(
  variable = c("mpg", "cyl", "disp", "hp"),
  description = c("Miles per gallon", "Cylinders", "Displacement", "Horsepower")
)

# ============================================================================
# PATTERN 1: Model Object (Automatic Extraction)
# ============================================================================
library(psych)
fa_model <- fa(mtcars[,1:4], nfactors = 2, rotate = "oblimin")

# S3 method automatically extracts loadings
result1 <- interpret(fa_model, variable_info = var_info,
                     llm_provider = "anthropic",
                     llm_model = "claude-haiku-4-5-20251001")

# ============================================================================
# PATTERN 2: Raw Data with model_type
# ============================================================================
# Extract loadings manually
loadings <- as.data.frame(unclass(fa_model$loadings))

# Interpret raw data by specifying model_type
result2 <- interpret(loadings, variable_info = var_info,
                     model_type = "fa",
                     llm_provider = "anthropic",
                     llm_model = "claude-haiku-4-5-20251001")

# ============================================================================
# PATTERN 3: Persistent Chat Session (Token-Efficient)
# ============================================================================
# Create persistent chat session
chat <- chat_session(model_type = "fa",
                     provider = "anthropic",
                     model = "claude-haiku-4-5-20251001")

# Use session as first argument (saves tokens on repeated analyses)
result3a <- interpret(chat, loadings, variable_info)
result3b <- interpret(chat, loadings2, variable_info2)  # Reuses system prompt

print(chat)  # Check cumulative token usage

# ============================================================================
# PATTERN 4: Raw Data with chat_session Parameter
# ============================================================================
result4 <- interpret(loadings, variable_info, chat_session = chat)
# Model type automatically inherited from chat session
}

\dontrun{
# Additional examples with other packages

# lavaan CFA
library(lavaan)
model_spec <- 'visual  =~ x1 + x2 + x3
               textual =~ x4 + x5 + x6
               speed   =~ x7 + x8 + x9'
fit <- cfa(model_spec, data = HolzingerSwineford1939)

var_info <- data.frame(
  variable = paste0("x", 1:9),
  description = paste("Indicator", 1:9)
)

result <- interpret(fit, variable_info = var_info,
                    llm_provider = "anthropic",
                    llm_model = "claude-haiku-4-5-20251001")
}
}
\seealso{
\code{\link{interpret_fa}} for the underlying interpretation function
}
