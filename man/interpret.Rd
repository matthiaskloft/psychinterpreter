% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interpret_method_dispatch.R
\name{interpret}
\alias{interpret}
\title{Interpret Psychometric Analysis Results}
\usage{
interpret(
  chat_session = NULL,
  model_fit = NULL,
  variable_info = NULL,
  model_type = NULL,
  ...
)
}
\arguments{
\item{chat_session}{Optional. A chat_session object created with \code{\link{chat_session}}
for token-efficient multi-analysis workflows.}

\item{model_fit}{One of:
\itemize{
\item Fitted model object (psych::fa, lavaan::cfa, mirt::mirt, etc.)
\item Raw data (loadings matrix as data.frame/matrix)
\item Structured list with model components (e.g., \code{list(loadings = ..., Phi = ...)})
}}

\item{variable_info}{Dataframe with 'variable' and 'description' columns describing the variables.}

\item{model_type}{Character. Type of analysis ("fa", "gm", "irt", "cdm"). Required when using
raw data without chat_session. Automatically inferred from chat_session if provided.}

\item{...}{Additional model-specific parameters:

\strong{LLM settings}:
\itemize{
\item llm_provider: l
\item lm_model:
}

\strong{Interpretation settings}:
\itemize{
\item cutoff:
\item n_emergency:
\item additional_info:
\item word_limit:
}

\strong{Report settings}:
\itemize{
\item max_line_length:
\item output_format:
\item heading_level:
\item suppress_heading
}

\strong{Verbosity settings}:
\itemize{
\item silent:
\item echo:
}

\strong{FA-specific} (see\code{\link[=interpret_fa]{interpret_fa()}}:
\itemize{
\item factor_cor_mat:
\item sort_loadings:
}}
}
\value{
Model-specific interpretation object:
\itemize{
\item FA: \code{fa_interpretation} (see \code{\link{interpret_fa}})
\item Future: \code{gm_interpretation}, \code{irt_interpretation}, etc.
}
}
\description{
Unified interface for interpreting psychometric analysis results with LLMs.
Supports fitted model objects, raw data with model_type specification,
structured lists, and persistent chat sessions for efficient multi-analysis workflows.
}
\details{
All arguments are named to prevent positional confusion. The function detects which pattern
you're using based on which arguments are provided.
\subsection{Usage Patterns}{

\strong{Pattern 1: Fitted Model Object}

Automatically extracts model components from fitted objects.

\preformatted{
interpret(
  model_fit = fa_model,
  variable_info = var_info,
  llm_provider = "ollama",
  llm_model = "gpt-oss:20b-cloud"
)
}

\strong{Pattern 2: Raw Data with model_type}

For custom data structures or manual extraction.

\preformatted{
interpret(
  model_fit = loadings_matrix,
  variable_info = var_info,
  model_type = "fa",
  llm_provider = "ollama",
  llm_model = "gpt-oss:20b-cloud"
)
}

\strong{Pattern 3: Structured List}

For FA: Provide loadings (required) and optionally Phi/factor_cor_mat.

\preformatted{
interpret(
  model_fit = list(
    loadings = loadings_matrix,
    Phi = factor_cor_mat
  ),
  variable_info = var_info,
  model_type = "fa"
)
}

\strong{Pattern 4: Chat Session (Token-Efficient)}

Reuse chat session across analyses to save tokens.

\preformatted{
chat <- chat_session(model_type = "fa", provider = "ollama", model = "gpt-oss:20b-cloud")
result1 <- interpret(chat_session = chat, model_fit = model1, variable_info = var_info1)
result2 <- interpret(chat_session = chat, model_fit = model2, variable_info = var_info2)
}
}

\subsection{Supported Model Types}{
\itemize{
\item \strong{fa} (Factor Analysis): psych::fa(), psych::principal(), lavaan::cfa/efa(), mirt::mirt()
\item \strong{gm} (Gaussian Mixture): Not yet implemented
\item \strong{irt} (Item Response Theory): Not yet implemented
\item \strong{cdm} (Cognitive Diagnosis Models): Not yet implemented
}
}
}
\examples{
\dontrun{
library(psych)
fa_model <- fa(mtcars[,1:4], nfactors = 2, rotate = "oblimin")

var_info <- data.frame(
  variable = c("mpg", "cyl", "disp", "hp"),
  description = c("Miles per gallon", "Cylinders", "Displacement", "Horsepower")
)

# Pattern 1: Fitted model
result1 <- interpret(
  model_fit = fa_model,
  variable_info = var_info,
  llm_provider = "ollama",
  llm_model = "gpt-oss:20b-cloud"
)

# Pattern 2: Raw data
loadings <- as.data.frame(unclass(fa_model$loadings))
result2 <- interpret(
  model_fit = loadings,
  variable_info = var_info,
  model_type = "fa",
  llm_provider = "ollama",
  llm_model = "gpt-oss:20b-cloud"
)

# Pattern 3: Structured list
result3 <- interpret(
  model_fit = list(
    loadings = loadings,
    Phi = fa_model$Phi
  ),
  variable_info = var_info,
  model_type = "fa",
  llm_provider = "ollama",
  llm_model = "gpt-oss:20b-cloud"
)

# Pattern 4: Chat session
chat <- chat_session(model_type = "fa", provider = "ollama", model = "gpt-oss:20b-cloud")
result4a <- interpret(chat_session = chat, model_fit = loadings, variable_info = var_info)
result4b <- interpret(chat_session = chat, model_fit = loadings2, variable_info = var_info2)
print(chat)  # Check token usage
}
}
\seealso{
\code{\link{interpret_fa}}, \code{\link{chat_session}}
}
