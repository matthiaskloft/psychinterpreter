% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generic_interpret.R
\name{interpret_generic}
\alias{interpret_generic}
\title{Core Interpretation Engine (Model-Agnostic)}
\usage{
interpret_generic(
  model_data,
  model_type = NULL,
  variable_info,
  llm_provider = "anthropic",
  llm_model = NULL,
  chat_session = NULL,
  word_limit = 100,
  additional_info = NULL,
  output_format = "text",
  heading_level = 1,
  suppress_heading = FALSE,
  max_line_length = 120,
  silent = FALSE,
  echo = "none",
  params = NULL,
  ...
)
}
\arguments{
\item{model_data}{List. Model-specific data structure (loadings, parameters, etc.)}

\item{model_type}{Character. Type of analysis ("fa", "gm", "irt", "cdm")}

\item{variable_info}{Data frame. Variable descriptions with 'variable' and 'description' columns}

\item{llm_provider}{Character. LLM provider (e.g., "anthropic", "openai", "ollama")}

\item{llm_model}{Character or NULL. Model name}

\item{chat_session}{Chat session object or NULL. If NULL, creates temporary session}

\item{word_limit}{Integer. Word limit for interpretations (default = 100)}

\item{additional_info}{Character or NULL. Additional context for LLM}

\item{output_format}{Character. Report format: "text" or "markdown" (default = "text")}

\item{heading_level}{Integer. Markdown heading level (default = 1)}

\item{suppress_heading}{Logical. Suppress report heading (default = FALSE)}

\item{max_line_length}{Integer. Maximum line length for text wrapping (default = 120)}

\item{silent}{Logical. Suppress status messages (default = FALSE)}

\item{echo}{Character. Echo level: "none", "output", "all" (default = "none")}

\item{params}{ellmer params object or NULL}

\item{...}{Additional arguments passed to model-specific methods}
}
\value{
Interpretation object with class c("\{model_type\}_interpretation", "interpretation", "list")
}
\description{
Generic interpretation engine that coordinates LLM-based analysis interpretation
for any model type. Delegates model-specific logic to S3 methods.
}
\details{
This function orchestrates the interpretation workflow:
\enumerate{
\item Build system prompt (model-specific via S3)
\item Initialize or use existing chat session
\item Build user prompt (model-specific via S3)
\item Send to LLM and get response
\item Parse JSON response (generic with model-specific validation)
\item Create diagnostics (model-specific via S3)
\item Build report (model-specific via S3)
\item Return interpretation object
}
}
\keyword{internal}
